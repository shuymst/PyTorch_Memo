{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1)\n",
    "y = torch.tensor([1])\n",
    "z = torch.tensor([[1]])\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.cat(tensors, dim=0)\n",
    "Concatenated tensors must have the same shape. <br>\n",
    "Tensors whose sizes are [] cannot be concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([[1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1)\n",
    "y = torch.tensor([1])\n",
    "z = torch.tensor([[1]])\n",
    "# print(torch.cat([x, x])) Error\n",
    "print(torch.cat([y, y]))\n",
    "print(torch.cat([z, z]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squeeze and unsqueeze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should distinguish between tensors of size [x] and tensors of size [1, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape : torch.Size([10])\n",
      "y's shape : torch.Size([1, 10])\n",
      "x_out : tensor([ 2.8576, -1.1859, -0.6926, -0.4234], grad_fn=<AddBackward0>)\n",
      "y_out : tensor([[ 2.8576, -1.1859, -0.6926, -0.4234]], grad_fn=<AddmmBackward0>)\n",
      "x_out's shape : torch.Size([4])\n",
      "y_out's shape : torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        return out\n",
    "\n",
    "model = Network()\n",
    "x = torch.tensor([1,3,2,4,5,1,2,10,2,3]).float()\n",
    "y = x.unsqueeze(dim=0)\n",
    "print(f\"x's shape : {x.shape}\")\n",
    "print(f\"y's shape : {y.shape}\")\n",
    "x_out = model(x)\n",
    "y_out = model(y)\n",
    "print(f\"x_out : {x_out}\")\n",
    "print(f\"y_out : {y_out}\")\n",
    "print(f\"x_out's shape : {x_out.shape}\")\n",
    "print(f\"y_out's shape : {y_out.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially you should be careful when comparing model's outputs and their target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.9639],\n",
      "        [ -9.2171],\n",
      "        [ -9.1887],\n",
      "        [  3.0913],\n",
      "        [-10.7156],\n",
      "        [  4.7492],\n",
      "        [ -1.5500],\n",
      "        [ -7.6851],\n",
      "        [ -6.7137],\n",
      "        [ -5.3190],\n",
      "        [-10.1170],\n",
      "        [ -3.2073],\n",
      "        [-12.6269],\n",
      "        [ -7.7646],\n",
      "        [  5.4059]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        return out\n",
    "\n",
    "model = Network()\n",
    "input_data = torch.randint(low=0, high=100, size=(15, 10)).float()\n",
    "outputs = model(input_data)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1])\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "target_values = torch.randint(low=-30, high=30, size=(15,))\n",
    "print(outputs.shape)\n",
    "print(target_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 15])\n"
     ]
    }
   ],
   "source": [
    "incorrect_mse_loss = (outputs - target_values) ** 2.0\n",
    "print(incorrect_mse_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "outputs = outputs.squeeze()\n",
    "print(outputs.shape == target_values.shape)\n",
    "correct_mse_loss = (outputs - target_values) ** 2.0\n",
    "print(correct_mse_loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### torch.max"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one dimentinal array case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5484, -0.8904,  2.0223,  0.9601])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_dimentinal = torch.randn(size=(4,))\n",
    "one_dimentinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0223)\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(one_dimentinal))\n",
    "print(torch.argmax(one_dimentinal))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi dimentional array case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9755,  0.3382,  0.4434, -0.8260],\n",
       "        [-0.3339, -0.2542,  1.7370, -0.3511],\n",
       "        [ 0.6496,  1.3269,  1.4022,  1.4153],\n",
       "        [-1.9361, -0.6137, -0.0198,  1.3351]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_dimentinal = torch.randn(size=(4, 4))\n",
    "multi_dimentinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7370)\n",
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(multi_dimentinal))\n",
    "print(torch.argmax(multi_dimentinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9755, 1.7370, 1.4153, 1.3351]),\n",
      "indices=tensor([0, 2, 3, 3]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.max(multi_dimentinal, dim=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.gather\n",
    "torch.gather is convenient when you extract specific action values from the outputs of Q-Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0962,  0.2107, -0.0853, -0.1119],\n",
      "        [-0.0509, -0.1319, -0.0826, -0.1039],\n",
      "        [-0.2024, -0.2447, -0.4339, -0.2535],\n",
      "        [-0.1886, -0.3505, -0.0699, -0.4098],\n",
      "        [-0.2471, -0.1916, -0.1524, -0.4220],\n",
      "        [-0.1830, -0.0300,  0.1245, -0.2025],\n",
      "        [-0.5126, -0.0266, -0.1706, -0.0860],\n",
      "        [ 0.1305, -0.3697, -0.2185, -0.5217],\n",
      "        [-0.0516, -0.2895, -0.0609, -0.3497],\n",
      "        [-0.0044, -0.2623, -0.3063, -0.6574]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        out = self.fc2(h)\n",
    "        return out\n",
    "\n",
    "model = QNetwork()\n",
    "x = torch.randn(size=(10, 128))\n",
    "out = model(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0962],\n",
       "        [-0.1319],\n",
       "        [-0.4339],\n",
       "        [-0.1886],\n",
       "        [-0.4220],\n",
       "        [ 0.1245],\n",
       "        [-0.0860],\n",
       "        [-0.2185],\n",
       "        [-0.2895],\n",
       "        [-0.0044]], grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_indexs = torch.tensor([0,1,2,0,3,2,3,2,1,0]).unsqueeze(1)\n",
    "out.gather(1, action_indexs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scatter_\n",
    "scatter_ can be used when you create two-hot representations of tensors as R2D2 or MuZero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([5.6, 2.4, 3.7, 4.1, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceil = x.ceil().long().unsqueeze(1)\n",
    "floor = x.floor().long().unsqueeze(1)\n",
    "ceil_values = (x.ceil() - x).unsqueeze(1)\n",
    "floor_values = (x - x.floor()).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6000, 0.4000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.7000, 0.3000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.9000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros(size=(5, 8))\n",
    "y.scatter_(dim=1, index=floor, src=floor_values)\n",
    "y.scatter_(dim=1, index=ceil, src=ceil_values)\n",
    "\n",
    "# x = torch.tensor([5.6, 2.4, 3.7, 4.1, 1.5])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.index_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = \n",
      "tensor([[ 1.5279,  0.4968,  0.8722, -0.1914],\n",
      "        [ 0.6810,  0.9399,  0.1952,  0.8909],\n",
      "        [-0.7884,  1.4546, -0.5774,  0.9142]])\n",
      "indices = [0, 2]\n",
      "dimention 0:\n",
      "tensor([[ 1.5279,  0.4968,  0.8722, -0.1914],\n",
      "        [-0.7884,  1.4546, -0.5774,  0.9142]])\n",
      "dimention 1:\n",
      "tensor([[ 1.5279,  0.8722],\n",
      "        [ 0.6810,  0.1952],\n",
      "        [-0.7884, -0.5774]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(\"x = \")\n",
    "print(x)\n",
    "indices = torch.tensor([0, 2])\n",
    "print(\"indices = [0, 2]\")\n",
    "print(\"dimention 0:\")\n",
    "print(torch.index_select(x, 0, indices))\n",
    "print(\"dimention 1:\")\n",
    "print(torch.index_select(x, 1, indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.fc1(x)\n",
    "        out = self.fc2(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2683, -1.1006,  0.1326, -0.4530, -0.7892],\n",
       "        [ 0.6995, -0.4313,  1.3323, -0.3492, -2.7021],\n",
       "        [ 0.5192,  0.0177,  1.1358, -0.3235,  0.3427],\n",
       "        [ 0.5555, -0.5110,  1.8292,  1.5230,  1.4374],\n",
       "        [ 0.1958,  2.5710,  1.6723, -0.1605,  1.6718],\n",
       "        [-0.0480, -1.1800, -0.3729,  1.3253,  0.4322],\n",
       "        [ 1.3606, -0.4978, -0.3857,  0.4112,  0.2754],\n",
       "        [-1.0308, -0.3386,  0.2789, -0.3737,  1.0994],\n",
       "        [ 0.4798,  2.0738,  0.1857,  1.4852,  0.4030],\n",
       "        [ 0.6676, -2.4768,  0.3229,  0.9359,  0.7048]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(10, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3014, -0.2413, -0.0759, -0.1829],\n",
      "        [ 0.6713, -0.0614,  0.3755, -0.4795],\n",
      "        [-0.4424, -0.2120,  0.0260, -0.1894],\n",
      "        [-0.5145, -0.1500, -0.5337, -0.0333],\n",
      "        [-1.1807, -0.2945,  0.0552, -0.3313],\n",
      "        [ 0.0864, -0.1423, -0.2924,  0.1772],\n",
      "        [-0.2198, -0.1294,  0.1410,  0.1377],\n",
      "        [-0.4826, -0.3182, -0.2228, -0.0543],\n",
      "        [-0.3224, -0.1292,  0.1182, -0.1112],\n",
      "        [-0.0462, -0.1348, -0.4220,  0.2235]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = Policy()\n",
    "logits = model(x)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3469, 0.2016, 0.2378, 0.2137],\n",
      "        [0.3936, 0.1891, 0.2928, 0.1245],\n",
      "        [0.1944, 0.2448, 0.3105, 0.2503],\n",
      "        [0.1985, 0.2857, 0.1947, 0.3211],\n",
      "        [0.1086, 0.2635, 0.3738, 0.2540],\n",
      "        [0.2797, 0.2225, 0.1915, 0.3063],\n",
      "        [0.2017, 0.2207, 0.2893, 0.2883],\n",
      "        [0.1996, 0.2353, 0.2588, 0.3063],\n",
      "        [0.1999, 0.2425, 0.3106, 0.2469],\n",
      "        [0.2557, 0.2340, 0.1756, 0.3348]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = F.softmax(logits, dim=1)\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 0, 3, 3, 3, 1, 3, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.distributions.categorical.Categorical(softmax)\n",
    "m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
